{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# PolitFact\n",
    "path = \"/root/lmy/ECFEND/formatted_data/declare/PolitiFact/mapped_data/5fold/\"\n",
    "\n",
    "llama2_filenames = ['llama2-7b_PolitiFact_test_0_result.tsv', 'llama2-7b_PolitiFact_test_1_result.tsv', 'llama2-7b_PolitiFact_test_2_result.tsv', 'llama2-7b_PolitiFact_test_3_result.tsv', 'llama2-7b_PolitiFact_test_4_result.tsv']\n",
    "llama3_filenames = ['llama3-13b_PolitiFact_test_0_result.tsv', 'llama3-13b_PolitiFact_test_1_result.tsv', 'llama3-13b_PolitiFact_test_2_result.tsv', 'llama3-13b_PolitiFact_test_3_result.tsv', 'llama3-13b_PolitiFact_test_4_result.tsv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC         0.531441\n",
      "f1-fake     0.567085\n",
      "f1-real     0.488863\n",
      "f1-macro    0.527974\n",
      "f1-micro    0.531441\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>f1-fake</th>\n",
       "      <th>f1-real</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>f1-micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.537267</td>\n",
       "      <td>0.579096</td>\n",
       "      <td>0.486207</td>\n",
       "      <td>0.532651</td>\n",
       "      <td>0.537267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.546729</td>\n",
       "      <td>0.593007</td>\n",
       "      <td>0.488576</td>\n",
       "      <td>0.540792</td>\n",
       "      <td>0.546729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.526480</td>\n",
       "      <td>0.548961</td>\n",
       "      <td>0.501639</td>\n",
       "      <td>0.525300</td>\n",
       "      <td>0.526480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.531153</td>\n",
       "      <td>0.563135</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.528626</td>\n",
       "      <td>0.531153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.515576</td>\n",
       "      <td>0.551227</td>\n",
       "      <td>0.473773</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.515576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC   f1-fake   f1-real  f1-macro  f1-micro\n",
       "0  0.537267  0.579096  0.486207  0.532651  0.537267\n",
       "1  0.546729  0.593007  0.488576  0.540792  0.546729\n",
       "2  0.526480  0.548961  0.501639  0.525300  0.526480\n",
       "3  0.531153  0.563135  0.494118  0.528626  0.531153\n",
       "4  0.515576  0.551227  0.473773  0.512500  0.515576"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['ACC', 'f1-fake', 'f1-real', 'f1-macro', 'f1-micro'])\n",
    "i = 0\n",
    "for filename in llama2_filenames:\n",
    "    df = pd.read_csv(path + filename, sep='\\t')\n",
    "    gt = df['label']\n",
    "    pred = df['prediction']\n",
    "    acc = accuracy_score(gt, pred)\n",
    "    f1_fake = f1_score(gt, pred, pos_label=False)\n",
    "    f1_real = f1_score(gt, pred, pos_label=True)\n",
    "    f1_macro = f1_score(gt, pred, average='macro')\n",
    "    f1_micro = f1_score(gt, pred, average='micro')\n",
    "    results.loc[i] = [acc, f1_fake, f1_real, f1_macro, f1_micro]\n",
    "    i += 1\n",
    "print(results.mean()) #llama2, PolitiFact\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC         0.638838\n",
      "f1-fake     0.656792\n",
      "f1-real     0.618859\n",
      "f1-macro    0.637826\n",
      "f1-micro    0.638838\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>f1-fake</th>\n",
       "      <th>f1-real</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>f1-micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.664596</td>\n",
       "      <td>0.679525</td>\n",
       "      <td>0.648208</td>\n",
       "      <td>0.663867</td>\n",
       "      <td>0.664596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.640187</td>\n",
       "      <td>0.658789</td>\n",
       "      <td>0.619440</td>\n",
       "      <td>0.639114</td>\n",
       "      <td>0.640187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.621495</td>\n",
       "      <td>0.637854</td>\n",
       "      <td>0.603589</td>\n",
       "      <td>0.620721</td>\n",
       "      <td>0.621495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.632399</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.630819</td>\n",
       "      <td>0.632399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.652819</td>\n",
       "      <td>0.616393</td>\n",
       "      <td>0.634606</td>\n",
       "      <td>0.635514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC   f1-fake   f1-real  f1-macro  f1-micro\n",
       "0  0.664596  0.679525  0.648208  0.663867  0.664596\n",
       "1  0.640187  0.658789  0.619440  0.639114  0.640187\n",
       "2  0.621495  0.637854  0.603589  0.620721  0.621495\n",
       "3  0.632399  0.654971  0.606667  0.630819  0.632399\n",
       "4  0.635514  0.652819  0.616393  0.634606  0.635514"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['ACC', 'f1-fake', 'f1-real', 'f1-macro', 'f1-micro'])\n",
    "i = 0\n",
    "for filename in llama3_filenames:\n",
    "    df = pd.read_csv(path + filename, sep='\\t')\n",
    "    gt = df['label']\n",
    "    pred = df['prediction']\n",
    "    acc = accuracy_score(gt, pred)\n",
    "    f1_fake = f1_score(gt, pred, pos_label=False)\n",
    "    f1_real = f1_score(gt, pred, pos_label=True)\n",
    "    f1_macro = f1_score(gt, pred, average='macro')\n",
    "    f1_micro = f1_score(gt, pred, average='micro')\n",
    "    results.loc[i] = [acc, f1_fake, f1_real, f1_macro, f1_micro]\n",
    "    i += 1\n",
    "print(results.mean()) #llama3, PolitiFact\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PolitFact\n",
    "path = \"/root/lmy/ECFEND/formatted_data/declare/Snopes/mapped_data/5fold/\"\n",
    "\n",
    "llama2_filenames = ['llama2-7b_Snopes_test_0_result.tsv', 'llama2-7b_Snopes_test_1_result.tsv', 'llama2-7b_Snopes_test_2_result.tsv', 'llama2-7b_Snopes_test_3_result.tsv', 'llama2-7b_Snopes_test_4_result.tsv']\n",
    "llama3_filenames = ['llama3-13b_Snopes_test_0_result.tsv', 'llama3-13b_Snopes_test_1_result.tsv', 'llama3-13b_Snopes_test_2_result.tsv', 'llama3-13b_Snopes_test_3_result.tsv', 'llama3-13b_Snopes_test_4_result.tsv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC         0.666069\n",
      "f1-fake     0.774415\n",
      "f1-real     0.357130\n",
      "f1-macro    0.565772\n",
      "f1-micro    0.666069\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>f1-fake</th>\n",
       "      <th>f1-real</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>f1-micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.605392</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.650895</td>\n",
       "      <td>0.762402</td>\n",
       "      <td>0.342169</td>\n",
       "      <td>0.552285</td>\n",
       "      <td>0.650895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.339806</td>\n",
       "      <td>0.551847</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.685019</td>\n",
       "      <td>0.787565</td>\n",
       "      <td>0.391089</td>\n",
       "      <td>0.589327</td>\n",
       "      <td>0.685019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.646607</td>\n",
       "      <td>0.764103</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.530010</td>\n",
       "      <td>0.646607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC   f1-fake   f1-real  f1-macro  f1-micro\n",
       "0  0.695652  0.794118  0.416667  0.605392  0.695652\n",
       "1  0.650895  0.762402  0.342169  0.552285  0.650895\n",
       "2  0.652174  0.763889  0.339806  0.551847  0.652174\n",
       "3  0.685019  0.787565  0.391089  0.589327  0.685019\n",
       "4  0.646607  0.764103  0.295918  0.530010  0.646607"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['ACC', 'f1-fake', 'f1-real', 'f1-macro', 'f1-micro'])\n",
    "i = 0\n",
    "for filename in llama2_filenames:\n",
    "    df = pd.read_csv(path + filename, sep='\\t')\n",
    "    gt = df['label']\n",
    "    pred = df['prediction']\n",
    "    acc = accuracy_score(gt, pred)\n",
    "    f1_fake = f1_score(gt, pred, pos_label=False)\n",
    "    f1_real = f1_score(gt, pred, pos_label=True)\n",
    "    f1_macro = f1_score(gt, pred, average='macro')\n",
    "    f1_micro = f1_score(gt, pred, average='micro')\n",
    "    results.loc[i] = [acc, f1_fake, f1_real, f1_macro, f1_micro]\n",
    "    i += 1\n",
    "print(results.mean()) #llama2, Snopes\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC         0.805524\n",
      "f1-fake     0.877869\n",
      "f1-real     0.522442\n",
      "f1-macro    0.700155\n",
      "f1-micro    0.805524\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>f1-fake</th>\n",
       "      <th>f1-real</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>f1-micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.813299</td>\n",
       "      <td>0.883200</td>\n",
       "      <td>0.535032</td>\n",
       "      <td>0.709116</td>\n",
       "      <td>0.813299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.787724</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>0.453947</td>\n",
       "      <td>0.661101</td>\n",
       "      <td>0.787724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.735285</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.875606</td>\n",
       "      <td>0.524691</td>\n",
       "      <td>0.700149</td>\n",
       "      <td>0.802817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.797695</td>\n",
       "      <td>0.871961</td>\n",
       "      <td>0.518293</td>\n",
       "      <td>0.695127</td>\n",
       "      <td>0.797695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC   f1-fake   f1-real  f1-macro  f1-micro\n",
       "0  0.813299  0.883200  0.535032  0.709116  0.813299\n",
       "1  0.787724  0.868254  0.453947  0.661101  0.787724\n",
       "2  0.826087  0.890323  0.580247  0.735285  0.826087\n",
       "3  0.802817  0.875606  0.524691  0.700149  0.802817\n",
       "4  0.797695  0.871961  0.518293  0.695127  0.797695"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['ACC', 'f1-fake', 'f1-real', 'f1-macro', 'f1-micro'])\n",
    "i = 0\n",
    "for filename in llama3_filenames:\n",
    "    df = pd.read_csv(path + filename, sep='\\t')\n",
    "    gt = df['label']\n",
    "    pred = df['prediction']\n",
    "    acc = accuracy_score(gt, pred)\n",
    "    f1_fake = f1_score(gt, pred, pos_label=False)\n",
    "    f1_real = f1_score(gt, pred, pos_label=True)\n",
    "    f1_macro = f1_score(gt, pred, average='macro')\n",
    "    f1_micro = f1_score(gt, pred, average='micro')\n",
    "    results.loc[i] = [acc, f1_fake, f1_real, f1_macro, f1_micro]\n",
    "    i += 1\n",
    "print(results.mean()) #llama3, Snopes\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PolitFact\n",
    "path = \"/root/lmy/ECFEND/formatted_data/declare/SnopesCG/mapped_data/5fold/\"\n",
    "\n",
    "llama2_filenames = ['llama2-7b_SnopesCG_test_0_result.tsv', 'llama2-7b_SnopesCG_test_1_result.tsv', 'llama2-7b_SnopesCG_test_2_result.tsv', 'llama2-7b_SnopesCG_test_3_result.tsv', 'llama2-7b_SnopesCG_test_4_result.tsv']\n",
    "llama3_filenames = ['llama3-13b_SnopesCG_test_0_result.tsv', 'llama3-13b_SnopesCG_test_1_result.tsv', 'llama3-13b_SnopesCG_test_2_result.tsv', 'llama3-13b_SnopesCG_test_3_result.tsv', 'llama3-13b_SnopesCG_test_4_result.tsv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC         0.570417\n",
      "f1-fake     0.680761\n",
      "f1-real     0.342575\n",
      "f1-macro    0.511668\n",
      "f1-micro    0.570417\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>f1-fake</th>\n",
       "      <th>f1-real</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>f1-micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.562889</td>\n",
       "      <td>0.683499</td>\n",
       "      <td>0.293763</td>\n",
       "      <td>0.488631</td>\n",
       "      <td>0.562889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.560399</td>\n",
       "      <td>0.674054</td>\n",
       "      <td>0.325048</td>\n",
       "      <td>0.499551</td>\n",
       "      <td>0.560399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.674095</td>\n",
       "      <td>0.353591</td>\n",
       "      <td>0.513843</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.574257</td>\n",
       "      <td>0.678505</td>\n",
       "      <td>0.369963</td>\n",
       "      <td>0.524234</td>\n",
       "      <td>0.574257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.587871</td>\n",
       "      <td>0.693652</td>\n",
       "      <td>0.370510</td>\n",
       "      <td>0.532081</td>\n",
       "      <td>0.587871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC   f1-fake   f1-real  f1-macro  f1-micro\n",
       "0  0.562889  0.683499  0.293763  0.488631  0.562889\n",
       "1  0.560399  0.674054  0.325048  0.499551  0.560399\n",
       "2  0.566667  0.674095  0.353591  0.513843  0.566667\n",
       "3  0.574257  0.678505  0.369963  0.524234  0.574257\n",
       "4  0.587871  0.693652  0.370510  0.532081  0.587871"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['ACC', 'f1-fake', 'f1-real', 'f1-macro', 'f1-micro'])\n",
    "i = 0\n",
    "for filename in llama2_filenames:\n",
    "    df = pd.read_csv(path + filename, sep='\\t')\n",
    "    gt = df['label']\n",
    "    gt = gt.replace('mostly false', 'false')\n",
    "    gt = gt.replace('mostly true', 'true')\n",
    "    gt = gt.replace('false', False)\n",
    "    gt = gt.replace('true', True)\n",
    "    pred = df['prediction']\n",
    "    acc = accuracy_score(gt, pred)\n",
    "    f1_fake = f1_score(gt, pred, pos_label=False)\n",
    "    f1_real = f1_score(gt, pred, pos_label=True)\n",
    "    f1_macro = f1_score(gt, pred, average='macro')\n",
    "    f1_micro = f1_score(gt, pred, average='micro')\n",
    "    results.loc[i] = [acc, f1_fake, f1_real, f1_macro, f1_micro]\n",
    "    i += 1\n",
    "print(results.mean()) #llama2, SnopesCG\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC         0.769596\n",
      "f1-fake     0.849229\n",
      "f1-real     0.510770\n",
      "f1-macro    0.680000\n",
      "f1-micro    0.769596\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>f1-fake</th>\n",
       "      <th>f1-real</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>f1-micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.764633</td>\n",
       "      <td>0.848193</td>\n",
       "      <td>0.476454</td>\n",
       "      <td>0.662324</td>\n",
       "      <td>0.764633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.778331</td>\n",
       "      <td>0.855285</td>\n",
       "      <td>0.526596</td>\n",
       "      <td>0.690940</td>\n",
       "      <td>0.778331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774074</td>\n",
       "      <td>0.851098</td>\n",
       "      <td>0.531969</td>\n",
       "      <td>0.691534</td>\n",
       "      <td>0.774074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.758663</td>\n",
       "      <td>0.839242</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.677685</td>\n",
       "      <td>0.758663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.852327</td>\n",
       "      <td>0.502703</td>\n",
       "      <td>0.677515</td>\n",
       "      <td>0.772277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC   f1-fake   f1-real  f1-macro  f1-micro\n",
       "0  0.764633  0.848193  0.476454  0.662324  0.764633\n",
       "1  0.778331  0.855285  0.526596  0.690940  0.778331\n",
       "2  0.774074  0.851098  0.531969  0.691534  0.774074\n",
       "3  0.758663  0.839242  0.516129  0.677685  0.758663\n",
       "4  0.772277  0.852327  0.502703  0.677515  0.772277"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['ACC', 'f1-fake', 'f1-real', 'f1-macro', 'f1-micro'])\n",
    "i = 0\n",
    "for filename in llama3_filenames:\n",
    "    df = pd.read_csv(path + filename, sep='\\t')\n",
    "    gt = df['label']\n",
    "    gt = gt.replace('mostly false', 'false')\n",
    "    gt = gt.replace('mostly true', 'true')\n",
    "    gt = gt.replace('false', False)\n",
    "    gt = gt.replace('true', True)\n",
    "    pred = df['prediction']\n",
    "    acc = accuracy_score(gt, pred)\n",
    "    f1_fake = f1_score(gt, pred, pos_label=False)\n",
    "    f1_real = f1_score(gt, pred, pos_label=True)\n",
    "    f1_macro = f1_score(gt, pred, average='macro')\n",
    "    f1_micro = f1_score(gt, pred, average='micro')\n",
    "    results.loc[i] = [acc, f1_fake, f1_real, f1_macro, f1_micro]\n",
    "    i += 1\n",
    "print(results.mean()) #llama3, SnopesCG\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lawliet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
